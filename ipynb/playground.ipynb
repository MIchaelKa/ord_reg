{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "published-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "supposed-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ordinary-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoralLayer(torch.nn.Module):\n",
    "    '''\n",
    "    Implements CORAL layer.\n",
    "    Look at arxiv paper for more details: https://arxiv.org/abs/1901.07884\n",
    "    This class is an adapted version from\n",
    "    https://github.com/Raschka-research-group/coral-pytorch\n",
    "    \n",
    "    Parameters:\n",
    "    - in_features: int\n",
    "        Number of features for the inputs to the forward method, which\n",
    "        are expected to have shape (num_examples, in_features).\n",
    "\n",
    "    - out_dim: int\n",
    "        Number of bins, it equals to the (num_classes - 1).\n",
    "\n",
    "    - preinit_bias: bool (default=True)\n",
    "        If true, it will pre-initialize the biases to descending values in\n",
    "        [0, 1] range instead of initializing it to all zeros. This pre-\n",
    "        initialization scheme results in faster learning and better\n",
    "        generalization performance in practice.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, in_features, out_dim, preinit_bias=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.coral_weights = torch.nn.Linear(in_features, 1, bias=False)\n",
    "        \n",
    "        if preinit_bias:\n",
    "            coral_bias = torch.arange(out_dim, 0, -1).float() / out_dim\n",
    "        else:\n",
    "            coral_bias = torch.zeros(out_dim).float()\n",
    "        \n",
    "        self.coral_bias = torch.nn.Parameter(coral_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.coral_weights(x) + self.coral_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "premium-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_in = 128\n",
    "num_classes = 10\n",
    "\n",
    "out_dim = 9\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "coral = CoralLayer(size_in, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "statistical-company",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 128])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 128)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "thirty-volume",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 9])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = coral(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "chubby-anger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.0000, 0.8889, 0.7778, 0.6667, 0.5556, 0.4444, 0.3333, 0.2222, 0.1111],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coral.coral_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "enabling-russell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5753,  0.4642,  0.3531,  0.2420,  0.1309,  0.0198, -0.0913, -0.2024,\n",
       "         -0.3136],\n",
       "        [ 0.4229,  0.3118,  0.2007,  0.0896, -0.0215, -0.1326, -0.2437, -0.3548,\n",
       "         -0.4660],\n",
       "        [ 0.6500,  0.5388,  0.4277,  0.3166,  0.2055,  0.0944, -0.0167, -0.1278,\n",
       "         -0.2389],\n",
       "        [ 0.8418,  0.7307,  0.6196,  0.5085,  0.3974,  0.2863,  0.1752,  0.0641,\n",
       "         -0.0470],\n",
       "        [ 0.6750,  0.5639,  0.4528,  0.3417,  0.2306,  0.1194,  0.0083, -0.1028,\n",
       "         -0.2139]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "beginning-manitoba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5753,  0.4642,  0.3531,  0.2420,  0.1309,  0.0198, -0.0913, -0.2024,\n",
       "         -0.3136],\n",
       "        [ 0.4229,  0.3118,  0.2007,  0.0896, -0.0215, -0.1326, -0.2437, -0.3548,\n",
       "         -0.4660],\n",
       "        [ 0.6500,  0.5388,  0.4277,  0.3166,  0.2055,  0.0944, -0.0167, -0.1278,\n",
       "         -0.2389],\n",
       "        [ 0.8418,  0.7307,  0.6196,  0.5085,  0.3974,  0.2863,  0.1752,  0.0641,\n",
       "         -0.0470],\n",
       "        [ 0.6750,  0.5639,  0.4528,  0.3417,  0.2306,  0.1194,  0.0083, -0.1028,\n",
       "         -0.2139]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acknowledged-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = torch.rand(5, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "changed-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "enormous-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "earned-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coral_loss(logits, levels, importance_weights=None, reduction='mean'):\n",
    "    \n",
    "    if not logits.shape == levels.shape:\n",
    "        raise ValueError(\"Please ensure that logits (%s) has the same shape as levels (%s). \"\n",
    "                         % (logits.shape, levels.shape))\n",
    "\n",
    "    term1 = F.logsigmoid(logits)*levels + (F.logsigmoid(logits) - logits)*(1-levels)\n",
    "\n",
    "    if importance_weights is not None:\n",
    "        term1 *= importance_weights\n",
    "\n",
    "    val = (-torch.sum(term1, dim=1))\n",
    "\n",
    "    if reduction == 'mean':\n",
    "        loss = torch.mean(val)\n",
    "    elif reduction == 'sum':\n",
    "        loss = torch.sum(val)\n",
    "    elif reduction is None:\n",
    "        loss = val\n",
    "    else:\n",
    "        s = ('Invalid value for `reduction`. Should be \"mean\", '\n",
    "             '\"sum\", or None. Got %s' % reduction)\n",
    "        raise ValueError(s)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eastern-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_bce(x, y):\n",
    "    \n",
    "    sigmoid = torch.sigmoid(x)\n",
    "   \n",
    "    \n",
    "    loss = y*torch.log(sigmoid) + (1 - y)*torch.log(1 - sigmoid)\n",
    "    \n",
    "    print(loss.shape)\n",
    "    \n",
    "#     loss = (-torch.sum(loss, dim=1))\n",
    "    \n",
    "    print(loss.shape)\n",
    "    \n",
    "    loss = torch.mean(loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "virtual-diving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.7110, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_bce(out, levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "natural-appreciation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7110, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(out, levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "convinced-anthropology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.3988, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coral_loss(out, levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-works",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
